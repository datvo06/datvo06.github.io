<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Bayesian synthesis of probabilistic programs for automatic data modeling | Dat Nguyen</title> <meta name="author" content="Thanh-Dat Nguyen"/> <meta name="description" content="a practical view of combining evidence with Bayesian reasoning"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üê≥</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://datvo06.github.io/blog/2026/bayesian-synthesis/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Dat Nguyen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Technical Blogs<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Bayesian synthesis of probabilistic programs for automatic data modeling</h1> <img class="post-header-image" src="https://raw.githubusercontent.com/datvo06/BayesianSynthesis/main/assets/log_run_viz/round_03_mutation.gif" alt="Bayesian synthesis of probabilistic programs for automatic data modeling"><p class="post-meta">January 23, 2026</p> <p class="post-tags"> <a href="/blog/2026"> <i class="fas fa-calendar fa-sm"></i> 2026 </a> </p> </header> <article class="post-content"> <p>Recently, I have been working on the how to combine program synthesis and probabilistic inference. Turns out that there are a variety of ways to do this:</p> <ol> <li>You can use apply probabilistic inference for program synthesis.</li> <li>You can apply program synthesis for probabilistic modeling.</li> <li>And finally, you can use probabilistic inference for program synthesis to synthesize probabilistic programs.</li> </ol> <p><a href="https://arxiv.org/abs/1907.06249" target="_blank" rel="noopener noreferrer">Bayesian Synthesis of Probabilistic Programs for Automatic Data Modeling</a> captures (3) quite nicely and in a self-contained manner. I tried reproducing (part of it) in a small notebook in <a href="https://github.com/datvo06/BayesianSynthesis" target="_blank" rel="noopener noreferrer">this repo</a>.</p> <p>While the notebook captures the implementation details of the paper, implementations aren‚Äôt everything: there are also theoretical foundations, what are some core assumptions? What are the settings in which this works well and not? I try to capture some of these in this post.</p> <h2 id="problem-statement">Problem statement</h2> <p>We start with two things:</p> <ol> <li>A language $\mathcal{L}$ (that we are going to formalize later with a Tagged <a href="https://en.wikipedia.org/wiki/Probabilistic_context-free_grammar" target="_blank" rel="noopener noreferrer">probabilistic context-free grammar</a>).</li> <li>A domain $\mathcal{X}$ (the space of data that we are going to model).</li> </ol> <p>The domain $\mathcal{X}$ is a set of data points $x \in \mathcal{X}$, and it also depends on which domain we are working with and is pretty straightforward to define, so we‚Äôll focus on the tough meat: the language‚Äôs semantics.</p> <h3 id="the-languages-semantics">The Language‚Äôs semantics</h3> <p>Let‚Äôs also say that everything in this language is an expression $E \in \mathcal{L}$. The paper would define two semantics associated with this language:</p> <ol> <li> <strong style="color: orange;">The prior semantic function</strong> $\texttt{Prior}: \mathcal{L} \to (0, 1]$ that calculate the prior probability of each expression.</li> <li> <strong style="color: orange;">The likelihood semantic function</strong> $\texttt{Lik}: \mathcal{L} \to (\mathcal{X} \to \mathbb{R}_{\geq 0})$ that calculate the likelihood of an expression given a data point. Here, $\mathbb{R}_{\geq 0}$ is the set of non-negative real numbers.</li> </ol> <p>Intuitively, the prior would say how likely an expression is to be generated from the language, and the likelihood would say, given expression $E$, how likely it is to generate a data point $x \in \mathcal{X}$.</p> <p>$\textbf{Bounded and Normalized}$: For the prior and likelihood to be well-defined probabilistic distributions, they must be bounded (there exists a finite upper bound) and normalized (all the probabilities sum to 1). A huge chunk of the paper is devoted to saying that:</p> <blockquote> <p>Given a Tagged PCFG $\mathcal{G}$, the prior and likelihood functions are bounded and normalized.</p> </blockquote> <p><strong style="color: orange;">Posterior semantic function</strong>: Given that both the prior $\texttt{Prior}$ and the likelihood $\texttt{Lik}$ are bounded and normalized, we can define the posterior semantic function $\texttt{Post}: \mathcal{L} \to (\mathcal{X} \to \mathbb{R}_{\geq 0})$. Recall that according to Bayes‚Äô rule: \(\mathsf{Post}\llbracket E \rrbracket(X) = \frac{\mathsf{Prior}\llbracket E \rrbracket \cdot \mathsf{Lik}\llbracket E \rrbracket(X)}{\sum_{E' \in \mathcal{L}} \mathsf{Prior}\llbracket E' \rrbracket \cdot \mathsf{Lik}\llbracket E' \rrbracket(X)}\) For each $X \in \mathcal{X}$, define $c_X ::= \sum\limits_{E \in \mathcal{L}}\mathsf{Lik}\llbracket E \rrbracket(X) \cdot \mathsf{Prior} \llbracket E \rrbracket$ to be the marginal probability of $X$ (which is finite by assumption). Then, we can rewrite the posterior semantic function as: \(\mathsf{Post}\llbracket E \rrbracket(X) = \frac{\mathsf{Prior}\llbracket E \rrbracket \cdot \mathsf{Lik}\llbracket E \rrbracket(X)}{c_X}\)</p> <p>Now we are finally ready to state the problem:</p> <p><em style="color: lightgreen;">Objective 3.5 (Bayesian Synthesis)</em> Let $\mathcal{L}$ be a language whose denotational semantics $\mathsf{Prior}$ and $\mathsf{Lik}$ satisfy 3.1., 3.2., and 3.3. Given a dataset $X \in \mathcal{X}$, generate expressions $E$ with probability $\mathsf{Post}\llbracket E \rrbracket(X)$.</p> <p>Bayesian relies on posterior distributions to infer new $E$, but here‚Äôs a problem: even though <span style="color: orange;"><em>$\mathsf{Post}\llbracket E \rrbracket(X)$</em></span> is bounded and normalized, <span style="color: orange;"><em>it is not tractable</em></span> to compute for all $E \in \mathcal{L}$ and $X \in \mathcal{X}$.</p> <h2 id="markov-chain-monte-carlo-to-the-rescue">Markov Chain Monte Carlo to the rescue</h2> <p>Bayesian inference doesn‚Äôt work if we can‚Äôt calculate the posterior distribution. But we do know how well each expression $E$ does at modeling the data point $X \in \mathcal{X}$. This is exactly the settings which Markov Chain Monte Carlo (MCMC) handles, specifically, the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" target="_blank" rel="noopener noreferrer">Metropolis-Hastings algorithm</a>. Only requires you to say how ‚Äúrelatively well‚Äù each sample is compared to the previous one, along with a proposal distribution that generate new sample from the previous one. For our case, we already know the likelihood <span style="color: orange;"><em>$\mathsf{Lik}\llbracket E \rrbracket(X)$</em></span>, we just need a proposal distribution $\mathcal{T}$ that generates new expressions $E‚Äô$ from the previous one $E$, conditioned on the language‚Äôs likelihood <span style="color: orange;"><em>$\mathsf{Lik}\llbracket E \rrbracket(X)$</em></span> and the language‚Äôs prior <span style="color: orange;"><em>$\mathsf{Prior}\llbracket E \rrbracket$</em></span>.</p> \[\begin{array}{l} \textbf{Algorithm 2: }\text{Metropolis-hasting-based sampling procedure}\\ \quad\textbf{Procedure }\text{Generate-New-Expression}(E, X)\\ \quad a \sim \text{SelectRandomElementUniformly}(A_E) \triangleright \color{orange}{\text{Randomly select a node in parse tree}}\\ \quad (N_i, E_{\text{hole}}) \leftarrow \text{Sever}_a\llbracket E \rrbracket \triangleright \color{orange}{\text{Sever the parse tree and return the non-terminal symbol at the sever point}}\\ \quad E_{\text{sub}} \sim \text{Expand}\llbracket \cdot \rrbracket(N_i) \triangleright \color{orange}{\text{Generate random } E_{\text{sub}} \text{ with probability } \text{Expand}\llbracket E_{\text{sub}} \rrbracket(N_i)}\\ \quad E' \leftarrow E_{\text{hole}}\llbracket E_{\text{sub}} \rrbracket \triangleright \color{orange}{\text{Fill hole in } E_{\text{hole}} \text{ with expression } E_{\text{sub}}}\\ \quad L \leftarrow \text{Lik}\llbracket E \rrbracket(X) \triangleright \color{orange}{\text{Evaluate likelihood for expression } E \text{ and data set } X}\\ \quad L' \leftarrow \text{Lik}\llbracket E' \rrbracket(X) \triangleright \color{orange}{\text{Evaluate likelihood for expression } E' \text{ and data set } X}\\ \quad p_{\text{accept}} \leftarrow \min\left\{1,\left(\lvert A_E\rvert/\lvert A_{E'}\rvert\right)\cdot(L'/L)\right\} \triangleright \color{orange}{\text{Compute the probability of accepting the mutation}}\\ \quad r \sim \text{UniformRandomNumber}([0, 1]) \triangleright \color{orange}{\text{Draw a random number from the unit interval}}\\ \quad \textbf{if } r &lt; p_{\text{accept}} \textbf{ then } \triangleright \color{orange}{\text{If-branch has probability } p_{\text{accept}}}\\ \quad\quad \textbf{return } E' \triangleright \color{orange}{\text{Accept and return the mutated expression}}\\ \quad \textbf{else } \triangleright \color{orange}{\text{Else-branch has probability } 1 - p_{\text{accept}}}\\ \quad\quad \textbf{return } E \triangleright \color{orange}{\text{Reject the mutated expression, and return the input expression}}\\ \end{array}\] <p>Let‚Äôs break this down:</p> <ol> <li>$\text{SelectRandomElementUniformly}(A_E)$ is a function that randomly selects a node in the parse tree $E$. When you have an expression $E$ defined in accordance with a PCFG, you can always pick a random terminal in the AST (the parse tree of the expression $E$).</li> <li>$\text{Sever}_a\llbracket E \rrbracket$ is a function that severs the parse tree $E$ at the node $a \in A_E$. Basically, one example of this is if you have an expression $E = (\cdot\ x\ y)$, and you select the node $a = (1)$ - meaning the 1st child of the root node, then $\text{Sever}_a\llbracket E \rrbracket = (Variable, (\cdot\ \square\ y)$. Where $Variable$ is a non-terminal symbol in the PCFG that are used to produce terms like $x, y, z$, etc.</li> <li>$\text{Expand}\llbracket \cdot \rrbracket(N_i)$ is a function that expands the non-terminal symbol $N_i$ in the parse tree $E$ in accordance with the PCFG‚Äôs probability distribution. We will be defining this below.</li> </ol> <p>$\color{lightgreen}Question$: Why it‚Äôs called algorithm 2? Why not algorithm 1?</p> <p>$\color{lightgreen}Answer$: Algorithm 1 is the main algorithm that uses algorithm 2!</p> <p>Markov Chain in general relies on drawing many samples from the chain to approximate the stationary distribution. The more samples we draw, the more accurate the approximation. So algorithm 1:</p> \[\begin{array}{l} \textbf{Algorithm 1: }\text{Template of MCMC for Bayesian Synthesis}\\ \quad\textbf{Procedure }\text{BAYESIAN-SYNTHESIS}(X, \mathcal{T}, n)\\ \qquad\textbf{do }\text{sample }E_0 \sim \mathsf{Prior}\llbracket E_0 \rrbracket \textbf{ while }\mathsf{Lik}\llbracket E_0 \rrbracket(X) = 0\\ \quad\textbf{for }i=1 \ldots n\textbf{: } E_i \sim \mathcal{T}(X, E)\\ \quad\textbf{return }E_n \end{array}\] <p>Metropolis-Hastings relies on the property that, if the chain is irreducible (does not have any absorbing states) and aperiodic (does not have any cycles), then it will converge to a unique stationary distribution. By defining the transition based on the PCFG‚Äôs proability distribution, we can guarantee that the chain is irreducible and aperiodic.</p> <h3 id="defining-textexpandllbracket-cdot-rrbracketn_i-and-mathcalt">Defining $\text{Expand}\llbracket \cdot \rrbracket(N_i)$ and $\mathcal{T}$</h3> <p>We will now define formally the prior $\mathsf{Prior}$ and then $\mathsf{Expand}\llbracket \cdot \rrbracket(N_i)$ accordingly. For that, we need to define a tagged probabilistic context-free grammar (PCFG) $G$, in the paper:</p> <blockquote> <p>$\color{lightgreen}\textbf{Definition 4.1. (Tagged PCFG with Random Symbols)}$. Let $G = \langle \Sigma, N, R, T, P, Q, S\rangle$ denote a tagged PCFG with terminals, non-terminals, and production rules.</p> <ul> <li>$\color{lightgreen}R ::= \{R_{ik} \mid i=1, \ldots, m; k=1, \ldots, r_i\}$ is a set of production rules, where $R_{ik}$ is the $k^\text{th}$ production rule of non-terminal $N_i$. Each production rule $R_{ik}$ is a tuple of the form:</li> </ul> \[R_{ik} ::= \langle N_i, T_{ik}, \tilde{N}_1, \ldots, \tilde{N}_{h_{ik}} \rangle \qquad \color{yellow}(6)\] <p>Where $h_{ik} \geq 0$ is the numer of non-terminal on the rhs. If the set of $\tilde{N}$ is not empty, this is called <em style="color: lightgreen;">recursive production rule</em>.</p> <ul> <li>$\color{lightgreen}T$ is a set of phrase tag symbols, disjoint from $N$, where $T_{ik}$ is a unique symbol identifying the production rule $R_{ik}$</li> <li>$\color{lightgreen}P: T \to (0, 1]$: phrase tag symbols to their probabilities.</li> <li>$\color{lightgreen}Q: T \times \Sigma \to [0, 1]$ map from phrase tags and terminal symbols to probabilities, where $Q(T_{ik}, s)$ is the probaiblity that production rule $R_{ik}$ of non-terminal $N_i$ draws the terminal symbol $s \in \Sigma$. For each tag $T_{ik}$, the probabilities over symbols sum to unity $\sum\limits_{s \in \Sigma}Q(T_{ik}, s) = 1$.</li> <li>$\color{lightgreen}S \in N$ is a designated start symbol.</li> </ul> <p>We additionally assume that grammar $G$ is proper: production rules must be cycle-free, and there are no useless symbols in $\Sigma \cup N \cup T$.</p> </blockquote> <p>Basically, we would have a probability assigned to each production rule $R_{ik}$ ($Q(T_{ik}, s)$) that say, ‚Äúhere is the probability that we would expand in this direction‚Äù, and also a prior to say which non-terminal symbol $N_i$ we would expand to ($P(T_{ik})$).</p> <p>$\color{lightgreen}\textbf{Expand:}$ Finally, $\mathsf{Expand}: \mathcal{L}(G) \to N \to [0, 1]$ is defined inductively: \(\begin{array}{c} \mathsf{Expand}\llbracket (T_{ik}\ s) \rrbracket (N_i) := P(T_{ik}) Q(T_{ik}, s)\\ \mathsf{Expand}\llbracket (T_{ik}\ E_1 \cdots E_{h_{ik}}) \rrbracket (N_i) := P(T_{ik}) \cdot \prod_{z=1}^{h_{ik}} \mathsf{Expand} \llbracket E_z \rrbracket (\tilde N _z) \end{array}\) Where $R_{ik} = (T_{ik}, N_i, \tilde{N}_1, \ldots, \tilde{N}_{h_{ik}})$, for $i= 1,\ldots, n$ and $k= 1, \ldots, r_i$.</p> <p>$\color{lightgreen}\textbf{Proposal Distribution/Transformation Operation }\mathcal{T}:$ How do we define the operation that gives us (1) a new expression $E‚Äô$ from the current expression $E$ (so that it creates a chain) and (2) gives us the probability how likely we can obtain $E‚Äô$ from $E$?</p> <p>The authors (Feras A. Saad et al.) deals with this by severing this ‚Äútransformation‚Äù (or as software engineer people often use the term ‚Äúmutation‚Äù since the original infamous <a href="https://web.eecs.umich.edu/~weimerw/p/weimer-tse2012-genprog.pdf" target="_blank" rel="noopener noreferrer">GenProg</a> paper) into two steps: <em style="color: lightgreen;">severing</em> and <em style="color: lightgreen;">expansion</em>.</p> <p>Intuitively, <em>severing</em> means that, taken an expression $E$, you cut out part of the expression. Specifically, this is done by first creating a set of all indices for each expression $E$. In the original paper:</p> <blockquote> <p>Define the set $A ::= {(a_1, a_2, \ldots, a_l) \mid a_i \in {1, 2, \ldots, h_{\max}}, l \in {0, 1, 2, \ldots, }}$ to be a countably infinite set that index the nodes in the parse tree of $E$, where $h_{\max}$ denotes the maximum number of symbols that appear on the right of any given production rule of the in $(6)$.</p> <p>Each element $a \in A$ is a sequence of sub-expression positions on the path from the root node of a parse tree to another node. For example, if $E = (t_0\ E_1\ E_2)$ where $E_1 = (t_1\ E_3\ E_4)$ and $E_2 = (t_2\ E_5\ E_6)$, then the root node of the parse tree has index $a_\text{root} ::= ()$; the node corresponding to $E_1$ has index $(1)$, the node corresponding to $E_2$ has index $(2)$; $E_3$ and $E_4$ are $(1, 1)$ and $(1, 2)$, respectively;</p> <p>and the nodes corresponding to $E_5$, $E_6$ have $(2, 1)$ and $(2,2)$. For an expression $E$, let $A_E \subset A$ denote the finite subset of nodes that exists within the parse tree of $E$.</p> </blockquote> <p>The description of $\mathsf{Sever}$ is very interesting, and I‚Äôd recommend checking it out later. But for now, check the intuitive image below:</p> <p><img src="/assets/img/BayesianSynthesis_Sever.jpg" alt="Sever operator illustration"></p> <p>Here, we would sever the first child of the root node, resulting in the $E_{\text{hole}} = (t_0\ \square\ E_2)$, $N_i$ would be the non-terminal symbol that produced $E_1$.</p> <p>In conjunction with $\mathsf{Sever}$, let us define $\mathsf{SubExpr}_a$ which is the sub-expression at the index $a$. $\mathsf{SubExpr}_a$ has to be well-defined, so for an index $a$ that is out of range, it should return the empty expression $\emptyset$, otherwise, is is inductively defined as follows: \(\mathsf{SubExpr}_a[\![(t\ E_1\ E_2\ \ldots\ E_l)]\!] ::= \left\{\begin{array}{ll} \emptyset&amp; \text{if \(a = ()\) or \(a_1 &gt; k\)}\\ E_j &amp; \text{if \(a = (j)\) for some $1 \leq j \leq k$} \\ \mathsf{SubExpr}_{(a_2, a_3, \ldots )} [\![E_j]\!] &amp; \text{if $i\neq (j)$ and $a_1 = j$ for some $1 \leq j \leq k$} \end{array}\right.\)</p> <p>What‚Äôs followed by severing? Finding a new $E_{sub}‚Äô$ to fill the hole. This is where the expansion comes in. From the severing process, we would have the non-terminal symbol $N_i$ that produced $E_1$. We would then expand $N_i$ in accordance with $\mathsf{Expand}\llbracket \cdot \rrbracket(N_i)$.</p> <p>Consider the probability that $\mathcal{T}$ takes an expression $E$ to another expression $E‚Äô$, which by total probability is an average over the uniformly chosen node index $a$: \(\mathcal{T}(X, E\to E') = \frac{1}{|A_E|} \sum\limits_{a \in A_E} \mathcal{T}(X, E \to E'; a) = \frac{1}{|A_E|} \sum\limits_{a \in A_E \cap A_{E'}} \mathcal{T}(X, E \to E'; a)\) where \(\mathcal{T}(X, E \to E', a) ::= \left\{ \begin{array}{l} \mathsf{Expand}\ [\![\mathsf{SubExpr}_a[\![E']\!]]\!](N_i) \cdot \alpha(E, E') + \mathbb{I}[E = E'](1 - \alpha(E, E'))\\ \qquad\ \text{ if \(\mathsf{Sever}_a[\![E]\!] = \mathsf{Sever}_a [\![E']\!] = (N_i, E_\text{hole}) \) for some $i$ and $E_\text{hole}$}\\ 0\qquad\text{otherwise} \end{array} \right.\) Note that we discard terms in the sum with $a \in A_E \setminus A_{E‚Äô}$ because for these terms $\mathsf{Sever}_a[![E‚Äô]!] =\emptyset$ and $\mathcal{T} (X, E\to E‚Äô; a) = 0$.</p> <p>This is the end. After this, the process is pretty straightforward: we would sample a new expression $E‚Äô$ from the current expression $E$ using the Metropolis-Hastings algorithm, and then we would accept or reject the new expression based on the probability of accepting the mutation (Algorithm 2). The process is repeated for $n$ times, and we would return the last expression $E_n$.</p> <h2 id="conclusion">Conclusion</h2> <p>I tried covering the paper from a top-down perspective and I also omitted lots of details. I remember that there are moment I read the paper and just gasped at the math and how cool it is. If you find this to be interesting, I‚Äôd recommend checking out the paper for more details.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2026 Thanh-Dat Nguyen. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams",inlineMath:[["$","$"],["\\(","\\)"]],macros:{llbracket:"\\lbrack\\!\\lbrack",rrbracket:"\\rbrack\\!\\rbrack"}}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>